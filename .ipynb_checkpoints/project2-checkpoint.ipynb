{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brush_teeth\n",
      "Climb_stairs\n",
      "Comb_hair\n",
      "Descend_stairs\n",
      "Drink_glass\n",
      "Eat_meat\n",
      "Eat_soup\n",
      "Getup_bed\n",
      "Liedown_bed\n",
      "Pour_water\n",
      "Sitdown_chair\n",
      "Standup_chair\n",
      "Use_telephone\n",
      "Walk\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from sklearn.cluster import KMeans\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "\n",
    "\n",
    "path = './HMP_Dataset'\n",
    " \n",
    "if len(sys.argv) == 2:\n",
    "    path = sys.argv[1]\n",
    " \n",
    " \n",
    "folder_labels = os.listdir(path)\n",
    "for name in folder_labels:\n",
    "    print(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./HMP_Dataset/Brush_teeth\n",
      "./HMP_Dataset/Climb_stairs\n",
      "./HMP_Dataset/Comb_hair\n",
      "./HMP_Dataset/Descend_stairs\n",
      "./HMP_Dataset/Drink_glass\n",
      "./HMP_Dataset/Eat_meat\n",
      "./HMP_Dataset/Eat_soup\n",
      "./HMP_Dataset/Getup_bed\n",
      "./HMP_Dataset/Liedown_bed\n",
      "./HMP_Dataset/Pour_water\n",
      "./HMP_Dataset/Sitdown_chair\n",
      "./HMP_Dataset/Standup_chair\n",
      "./HMP_Dataset/Use_telephone\n",
      "./HMP_Dataset/Walk\n"
     ]
    }
   ],
   "source": [
    "file_path = []\n",
    "full_label = []\n",
    "for label in folder_labels:\n",
    "    if label[0] != '.':\n",
    "        check = './HMP_Dataset/' + label\n",
    "        print(check)\n",
    "        if len(sys.argv) == 2:\n",
    "\n",
    "            check =   sys.argv[1]  \n",
    "\n",
    "        file_path +=  os.listdir(check)\n",
    "\n",
    "c = 0\n",
    "while c < 12:\n",
    "    b = file_path[c]\n",
    "    f = './HMP_Dataset/Brush_teeth/' + b\n",
    "    file_path[c] = f\n",
    "    f = ''\n",
    "    full_label.append(\"Brush_teeth\")\n",
    "    c += 1\n",
    "\n",
    "while c < 114:\n",
    "    b = file_path[c]\n",
    "    f = './HMP_Dataset/Climb_stairs/' + b\n",
    "    file_path[c] = f\n",
    "    f = ''\n",
    "    full_label.append(\"Climb_stairs\")\n",
    "    c += 1\n",
    "    \n",
    "\n",
    "while c < 145:\n",
    "    b = file_path[c]\n",
    "    f = './HMP_Dataset/Comb_hair/' + b\n",
    "    file_path[c] = f\n",
    "    f = ''\n",
    "    full_label.append(\"Comb_hair\")\n",
    "    c += 1\n",
    "\n",
    "while c < 187:\n",
    "    b = file_path[c]\n",
    "    f = './HMP_Dataset/Descend_stairs/' + b\n",
    "    file_path[c] = f\n",
    "    f = ''\n",
    "    full_label.append(\"Descend_stairs\")\n",
    "    c += 1\n",
    "\n",
    "while c < 287:\n",
    "    b = file_path[c]\n",
    "    f = './HMP_Dataset/Drink_glass/' + b\n",
    "    file_path[c] = f\n",
    "    f = ''\n",
    "    full_label.append(\"Drink_glass\")\n",
    "    c += 1\n",
    "    \n",
    "while c < 292:\n",
    "    b = file_path[c]\n",
    "    f = './HMP_Dataset/Eat_meat/' + b\n",
    "    file_path[c] = f\n",
    "    f = ''\n",
    "    full_label.append(\"Eat_meat\")\n",
    "    c += 1\n",
    "    \n",
    "while c < 295:\n",
    "    b = file_path[c]\n",
    "    f = './HMP_Dataset/Eat_soup/' + b\n",
    "    file_path[c] = f\n",
    "    f = ''\n",
    "    full_label.append(\"Eat_soup\")\n",
    "    c += 1\n",
    "    \n",
    "while c < 396:\n",
    "    b = file_path[c]\n",
    "    f = './HMP_Dataset/Getup_bed/' + b\n",
    "    file_path[c] = f\n",
    "    f = ''\n",
    "    full_label.append(\"Getup_bed\")\n",
    "    c += 1\n",
    "    \n",
    "while c < 424:\n",
    "    b = file_path[c]\n",
    "    f = './HMP_Dataset/Liedown_bed/' + b\n",
    "    file_path[c] = f\n",
    "    f = ''\n",
    "    full_label.append(\"Liedown_bed\")\n",
    "    c += 1\n",
    "\n",
    "while c < 524:\n",
    "    b = file_path[c]\n",
    "    f = './HMP_Dataset/Pour_water/' + b\n",
    "    file_path[c] = f\n",
    "    f = ''\n",
    "    full_label.append(\"Pour_water\")\n",
    "    c += 1\n",
    "    \n",
    "while c < 624:\n",
    "    b = file_path[c]\n",
    "    f = './HMP_Dataset/Sitdown_chair/' + b\n",
    "    file_path[c] = f\n",
    "    f = ''\n",
    "    full_label.append(\"Sitdown_chair\")\n",
    "    c += 1\n",
    "    \n",
    "while c < 726:\n",
    "    b = file_path[c]\n",
    "    f = './HMP_Dataset/Standup_chair/' + b\n",
    "    file_path[c] = f\n",
    "    f = ''\n",
    "    full_label.append(\"Standup_chair\")\n",
    "    c += 1\n",
    "\n",
    "while c < 739:\n",
    "    b = file_path[c]\n",
    "    f = './HMP_Dataset/Use_telephone/' + b\n",
    "    file_path[c] = f\n",
    "    f = ''\n",
    "    full_label.append(\"Use_telephone\")\n",
    "    c += 1\n",
    "    \n",
    "while c < 839:\n",
    "    b = file_path[c]\n",
    "    f = './HMP_Dataset/Walk/' + b\n",
    "    file_path[c] = f\n",
    "    f = ''\n",
    "    full_label.append(\"Walk\")\n",
    "    c += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "brush = []\n",
    "climb = []\n",
    "comb = []\n",
    "descend = []\n",
    "drink = []\n",
    "meat  = []\n",
    "soup = []\n",
    "upbed = []\n",
    "downbed = []\n",
    "pour = []\n",
    "sitchair = []\n",
    "standchair = []\n",
    "telephone = []\n",
    "walk = []\n",
    "chunk_cluster_by_file = []\n",
    "# process chunk from quantize_file function\n",
    "def process_chunk(chop_file, filetype): \n",
    "\n",
    "    p = np.array(chop_file)\n",
    "\n",
    "    p = p.flatten()  \n",
    "\n",
    "    \n",
    "    filetype.append(p)\n",
    "    \n",
    "\n",
    "# this will split chunks by input num_seconds\n",
    "def quantize_file(filepath, num_seconds, filetype):\n",
    "    \n",
    "    #df = pd.read_csv(filepath, header = None)    \n",
    "    \n",
    "    lines = []\n",
    "    num_chunk_in_file = 0\n",
    "    \n",
    "    with open(filepath) as csvfile:\n",
    "        reader = csv.reader(csvfile, quoting=csv.QUOTE_NONNUMERIC, delimiter = ' ') # change contents to floats\n",
    "        for row in reader: # each row is a list\n",
    "            lines.append(row)\n",
    "            \n",
    "            \n",
    "    \n",
    "    if len(lines) % num_seconds != 0:\n",
    "        while len(lines) % num_seconds != 0:\n",
    "            del lines[-1]\n",
    "\n",
    "    chunk = []\n",
    "    counter = 0\n",
    "    for i in lines:\n",
    "        chunk.append(i)\n",
    "        counter += 1\n",
    "        \n",
    "        if (counter % num_seconds) == 0:\n",
    "            process_chunk(chunk, filetype)\n",
    "            chunk.clear()\n",
    "            num_chunk_in_file += 1\n",
    "    \n",
    "     \n",
    "    chunk_cluster_by_file.append(num_chunk_in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=200, n_init=1, n_jobs=None, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0;\n",
    "for file in file_path:\n",
    "    \n",
    "    if full_label[count] == 'Brush_teeth':\n",
    "        quantize_file(file, 32, brush)\n",
    "        \n",
    "    if full_label[count] == 'Climb_stairs':\n",
    "        quantize_file(file, 32, climb)\n",
    "        \n",
    "    if full_label[count] == 'Comb_hair':\n",
    "        quantize_file(file, 32, comb)\n",
    "        \n",
    "    if full_label[count] == 'Descend_stairs':\n",
    "        quantize_file(file, 32, descend)\n",
    "        \n",
    "    if full_label[count] == 'Drink_glass':\n",
    "        quantize_file(file, 32, drink)\n",
    "        \n",
    "    if full_label[count] == 'Eat_meat':\n",
    "        quantize_file(file, 32, meat)\n",
    "        \n",
    "    if full_label[count] == 'Eat_soup':\n",
    "        quantize_file(file, 32, soup)\n",
    "        \n",
    "    if full_label[count] == 'Getup_bed':\n",
    "        quantize_file(file, 32, upbed)\n",
    "        \n",
    "    if full_label[count] == 'Liedown_bed':\n",
    "        quantize_file(file, 32, downbed)\n",
    "        \n",
    "    if full_label[count] == 'Pour_water':\n",
    "        quantize_file(file, 32, pour)\n",
    "        \n",
    "    if full_label[count] == 'Sitdown_chair':\n",
    "        quantize_file(file, 32, sitchair)\n",
    "        \n",
    "    if full_label[count] == 'Standup_chair':\n",
    "        quantize_file(file, 32, standchair)\n",
    "        \n",
    "    if full_label[count] == 'Use_telephone':\n",
    "        quantize_file(file, 32, telephone)\n",
    "        \n",
    "    if full_label[count] == 'Walk':\n",
    "        quantize_file(file, 32, walk)\n",
    "        \n",
    "    count += 1;\n",
    "\n",
    "all_list = []\n",
    "all_list = all_list + brush\n",
    "all_list = all_list + (climb)\n",
    "all_list = all_list + (comb)\n",
    "all_list= all_list + (descend)\n",
    "all_list= all_list + (drink)\n",
    "all_list= all_list + (meat)\n",
    "all_list= all_list + (soup)\n",
    "all_list= all_list + (upbed)\n",
    "all_list= all_list + (downbed)\n",
    "all_list= all_list + (pour)\n",
    "all_list= all_list + (sitchair)\n",
    "all_list= all_list + (standchair)\n",
    "all_list= all_list + (telephone)\n",
    "all_list= all_list + (walk)\n",
    "\n",
    "a = np.array(all_list)\n",
    "\n",
    "n_clusters = 200\n",
    "\n",
    "k_m = KMeans(n_clusters = n_clusters, n_init = 1)\n",
    "k_m.fit(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_file(filetype):\n",
    "    print(file)\n",
    "    temp = [0] * n_clusters\n",
    "    chunk_counter = 0\n",
    "    num = len(filetype) / number_chunk\n",
    "    file_num = 0\n",
    "    for u in filetype:\n",
    "        u = u.reshape(-1,1)\n",
    "        val = k_m.predict(u)\n",
    "        temp[val] += 1\n",
    "        chunk_counter +=1\n",
    "        \n",
    "        if chunk_counter == chunk_cluster_by_file[file_num]:\n",
    "            features.append(temp)\n",
    "            temp.clear()\n",
    "            temp = [0] * n_clusters\n",
    "            chunk_counter = 0\n",
    "            file_num += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Incorrect number of features. Got 1 features, expected 96",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-76-69de2bcb6eae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredict_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbrush\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbrush_chunk_number\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpredict_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclimb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclimb_chunk_number\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpredict_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomb_chunk_number\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpredict_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdescend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescend_chunk_number\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpredict_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrink\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrink_chunk_number\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-75-f8b5f5dfe875>\u001b[0m in \u001b[0;36mpredict_file\u001b[1;34m(filetype, number_chunk)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mu\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfiletype\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mk_m\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mtemp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mchunk_counter\u001b[0m \u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\k_means_.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, sample_weight)\u001b[0m\n\u001b[0;32m   1074\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cluster_centers_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1075\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1076\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_test_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1077\u001b[0m         \u001b[0mx_squared_norms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow_norms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1078\u001b[0m         return _labels_inertia(X, sample_weight, x_squared_norms,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\k_means_.py\u001b[0m in \u001b[0;36m_check_test_data\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    937\u001b[0m             raise ValueError(\"Incorrect number of features. \"\n\u001b[0;32m    938\u001b[0m                              \"Got %d features, expected %d\" % (\n\u001b[1;32m--> 939\u001b[1;33m                                  n_features, expected_n_features))\n\u001b[0m\u001b[0;32m    940\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Incorrect number of features. Got 1 features, expected 96"
     ]
    }
   ],
   "source": [
    "predict_file(brush)\n",
    "predict_file(climb)\n",
    "predict_file(comb)\n",
    "predict_file(descend)\n",
    "predict_file(drink)\n",
    "predict_file(meat)\n",
    "predict_file(soup)\n",
    "predict_file(upbed)\n",
    "predict_file(downbed)\n",
    "predict_file(pour)\n",
    "predict_file(sitchair)\n",
    "predict_file(standchair)\n",
    "predict_file(telephone)\n",
    "predict_file(walk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
